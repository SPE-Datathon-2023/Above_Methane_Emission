{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating png images from tif files / Background removal\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Installing extra libraries.\n",
    "!pip3 install pandas matplotlib seaborn numpy xlrd  Pillow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup, data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining paths for the permian dataset + loading the csv files as dataframes\n",
    "\n",
    "\n",
    "permian_plume_file =\"dataset/permian_plume_list_2019 Jeremy Zhao.csv\"\n",
    "permian_source_list = \"dataset/permian_source_list_2019 Jeremy Zhao.csv\"\n",
    "permian_png_file_path=\"dataset/ch4_plume_permian_2019_png/permian_2019_png/\"\n",
    "permian_tiff_file_path=\"support_data/permian_2019/permian_2019/\"\n",
    "\n",
    "tiff_file_path_5606120=\"support_data/5606120_carbonmapper_ch4_rgb_geotiffs_2020_2021/carbonmapper_ch4_rgb_geotiffs_2020_2021\"\n",
    "tiff_file_path_7072824=\"support_data/7072824_carbonmapper_ch4_rgb_geotiffs_2020_2021/carbonmapper_ch4_rgb_geotiffs_2020_2021\"\n",
    "\n",
    "# Output folder for the generated pngs\n",
    "generated_dataset_5606120= \"generated_dataset_5606120\"\n",
    "generated_dataset_7072824= \"generated_dataset_5606120\"\n",
    "generated_dataset_permian = \"generated_dataset_permian\"\n",
    "\n",
    "# Tabular data for the addtionnal datasets\n",
    "plume_file_5606120 =\"support_data/5606120_carbonmapper_ch4_plumelist_2020_2021.xls\"\n",
    "plume_file_7072824 =\"support_data/7072824_carbonmapper_ch4_plumelist_2020_2021.xls\"\n",
    "\n",
    "# Reading tabular files\n",
    "df_permian_plume = pd.read_csv(permian_plume_file)\n",
    "df_permian_source = pd.read_csv(permian_source_list)\n",
    "\n",
    "df_5606120_plume = pd.read_excel(plume_file_5606120,sheet_name='carbonmapper_ch4_plumelist_2020')\n",
    "df_7072824_plume = pd.read_excel(plume_file_7072824,sheet_name='carbonmapper_ch4_plumelist_2020')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
     ]
    }
   ],
   "source": [
    "## Browsing through the tif files to find the images associated to the dataframe entries\n",
    "import os\n",
    "all_permian_png_files = os.listdir(permian_tiff_file_path)\n",
    "\n",
    "for index, row in df_permian_plume.iterrows():\n",
    "    for file in all_permian_png_files:\n",
    "        if row[\"candidate_id\"] in file:\n",
    "            # print(\"found \" + file)\n",
    "            if\"ctr.tif\" in file:\n",
    "                df_permian_plume.at[index,\"ctr\"]=file\n",
    "            elif \"rgb.tif\" in file:\n",
    "                df_permian_plume.at[index,\"rgb\"]=file\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Method used to extract the filenames from the additional tabular data\n",
    "def extract_tiff_filenames(df):\n",
    "    for index, row in df.iterrows():\n",
    "      a = row[\"file_names\"].split( \"'\")[1]\n",
    "      b = row[\"file_names\"].split( \"'\")[3]\n",
    "      if 'ctr.tif' in a:\n",
    "          df.at[index,\"ctr\"]=a\n",
    "          df.at[index,\"rgb\"]=b\n",
    "      else :\n",
    "          df.at[index,\"ctr\"]=b\n",
    "          df.at[index,\"rgb\"]=a\n",
    "\n",
    "extract_tiff_filenames(df_5606120_plume)\n",
    "extract_tiff_filenames(df_7072824_plume)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "## Showing some images of the dataset, as CTR (plume)\n",
    "def show_some_images(df, n):\n",
    "    i = 0\n",
    "    for index, row in df.sort_values(by=\"qplume\").iterrows():\n",
    "        if i < n:\n",
    "            print(\"{} {} {} qplume={} sigma_qplume={} \".format(row[\"date\"],row[\"time\"],row[\"candidate_id\"],row[\"qplume\"],row[\"sigma_qplume\"]))\n",
    "            img = plt.imread(permian_tiff_file_path+row[\"ctr\"])\n",
    "            plt.imshow(img)\n",
    "            plt.show()\n",
    "            i+=1\n",
    "        else:\n",
    "            break\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Dataset generation"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "# Generating the actual dataset, combining backround and plume data\n",
    "\n",
    "generated_dataset_5606120= \"generated_dataset_5606120\"\n",
    "generated_dataset_7072824= \"generated_dataset_7072824\"\n",
    "generated_dataset_permian = \"generated_dataset_permian\"\n",
    "\n",
    "! mkdir -p \"generated_dataset_permian\"\n",
    "! mkdir -p \"generated_dataset_7072824\"\n",
    "! mkdir -p \"generated_dataset_5606120\"\n",
    "\n",
    "generated_dataset_permian = \"generated_dataset_permian/\""
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Opening background (rgb) and plume (ctr) files, merging them into one (151,151,4) png image\n",
    "\n",
    "def generate_dataset(df, tiff_folder, output_folder):\n",
    "    for index, row in df.iterrows():\n",
    "\n",
    "        img1 = Image.open(os.path.join(tiff_folder,row[\"rgb\"]))\n",
    "        print(os.path.join(tiff_folder,row[\"rgb\"]))\n",
    "\n",
    "        # Opening the secondary image (overlay image)\n",
    "        img2 = Image.open(os.path.join(tiff_folder,row[\"ctr\"]))\n",
    "        img2.resize((151,151))\n",
    "\n",
    "        final1 = Image.new(\"RGBA\", img1.size)\n",
    "        final1.paste(img1, (0,0), img1.convert('RGBA'))\n",
    "        final1.paste(img2, (0,0), img2)\n",
    "\n",
    "\n",
    "        final1.save(os.path.join(output_folder,row[\"rgb\"][:-7]+\".png\"),bbox_inches='tight', pad_inches=0,)\n",
    "        img1.close()\n",
    "        img2.close()\n",
    "        final1.close()\n",
    "\n",
    "        if index % 10 == 0:\n",
    "            print(\"{}/{}\".format(index, df.shape[0]))\n",
    "\n",
    "        # Updating the dataframe with the new png file\n",
    "        df.at[index,\"gen_png\"]=row[\"rgb\"][:-7]+\".png\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
  
   ],
   "source": [
    "generate_dataset(df_permian_plume, permian_tiff_file_path, generated_dataset_permian)\n",
    "generate_dataset(df_7072824_plume, tiff_file_path_7072824, generated_dataset_7072824)\n",
    "generate_dataset(df_5606120_plume,tiff_file_path_5606120,  generated_dataset_5606120)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the dataframe as a csv file\n",
    "df_permian_plume.to_csv(permian_plume_file[:-4]+\"_generated_files.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "## Background removal"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Generate hex value from pixel value with alpha layer\n",
    "def match_rgba(data, px, py):\n",
    "    return hex(data[px][py][0] * 256 * 256 * 256 + data[px][py][1] *256 *256+ data[px][py][2]*256+data[px][py][3])\n",
    "\n",
    "\n",
    "# Generate hex value from pixel value without alpha layer\n",
    "def match_rgb(data, px, py):\n",
    "    return hex(data[px][py][0] * 256 * 256  + data[px][py][1] *256 + data[px][py][2])\n",
    "\n",
    "# Generate a dictionnary with a RGBA hex value as a key, the amount of pixels having this RGBA value in the image\n",
    "def image_to_dict(path, image_name):\n",
    "    dict = {}\n",
    "    image = Image.open(path+image_name)\n",
    "    data = asarray(image)\n",
    "    for px in range(data.shape[0]):\n",
    "        for py in range(data.shape[1]):\n",
    "            match = match_rgb(data,px, py)\n",
    "            if match in dict :\n",
    "                dict[match] += 1\n",
    "            else :\n",
    "                dict[match] = 1\n",
    "    return dict\n",
    "\n",
    "# Find all the RGBA unique values from the CTR dataset, on order to know which colors belong to the plume colorscale\n",
    "\n",
    "base_dict = {}\n",
    "nb_image = 2000\n",
    "index = 0\n",
    "for i in range(nb_image):\n",
    "    index +=1\n",
    "    if index % 10 == 0 :\n",
    "        print(\"{}/{}\".format(index, nb_image))\n",
    "    d0 = image_to_dict(permian_tiff_file_path,df_permian_plume.at[i,\"ctr\"])\n",
    "    for k in d0.keys():\n",
    "        if k in base_dict.keys():\n",
    "            base_dict[k]+= d0[k]\n",
    "        else:\n",
    "            base_dict[k] = d0[k]\n",
    "\n",
    "dict = {k: v for k, v in sorted(base_dict.items(), key=lambda item: item[1])}\n",
    "threshold = 100\n",
    "\n",
    "\n",
    "selected_keys = [k for k, v in sorted(base_dict.items(), key=lambda item: item[1]) if v > 1 and k != 0x0 ]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "outputs": [],
   "source": [
    "selected_keys = selected_keys[:-1] # Removing the 0x0 key\n",
    "file = open('selected_rgb_keys.pkl', 'wb')\n",
    "# Saving this dictionnary\n",
    "pickle.dump(selected_keys, file)\n",
    "file.close()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "outputs": [],
   "source": [
    "file = open('selected_rgb_keys.pkl', 'rb')\n",
    "\n",
    "# dump information to that file\n",
    "selected_keys = pickle.load(file)\n",
    "file.close()\n",
    "\n",
    "\n",
    "# Given a new image, we set to 0 the pixel having RGBA values not in the selected_keys dictionnary\n",
    "# This removes all the pixels not belonging to the plume colorscale\n",
    "def remove_backgroung(folder, filenames):\n",
    "    for filename in filenames:\n",
    "        full_path = os.path.join(folder, filename)\n",
    "        image = Image.open(full_path)\n",
    "        plt.imshow(image)\n",
    "        plt.show()\n",
    "        data = np.array(Image.open(full_path))\n",
    "        print(data.shape)\n",
    "        for px in range(data.shape[0]):\n",
    "            for py in range(data.shape[1]):\n",
    "                match = match_rgb(data,px, py)\n",
    "                if match not in selected_keys:\n",
    "                     data[px][py][0]=0\n",
    "                     data[px][py][1]=0\n",
    "                     data[px][py][2]=0\n",
    "                     data[px][py][3]=255\n",
    "        new_image = Image.fromarray(data)\n",
    "        plt.imshow(new_image)\n",
    "        plt.show()\n",
    "        plt.clf()\n",
    "\n",
    "## Trying the algorithme on a sub sample of the dataset\n",
    "gen_images = []\n",
    "for i in range(10,15):\n",
    "     gen_images.append(df_permian_plume.at[i,\"gen_png\"])\n",
    "\n",
    "remove_backgroung(generated_dataset_permian, gen_images)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
